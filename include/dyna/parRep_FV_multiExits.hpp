/**
 * \file parRep_FV_multiExits.hpp
 * \copyright The 3-clause BSD license is applied to this software.
 * \author Florent Hédin
 * \author Tony Lelièvre
 * \author École des Ponts - ParisTech
 * \date 2016-2018
 */

#ifndef PARREP_FV_MULTI_HPP_INCLUDED
#define PARREP_FV_MULTI_HPP_INCLUDED

#include "parRep_FV.hpp"

/**
 * @brief This class represents a parRep simulation using a Fleming Viot particle process in order to converge to the QSD
 * Convergence is achieved by using Gelman Rubin statistics.
 * 
 * With this variant multiple exit times are computed in the parallel phase of the algorithm,
 * i.e. the algorithm does not stop on the first exit time (user chooses how many are computed before stopping and generating again initial conditions using the FV procedure)
 * 
 */
class ParRepFV_multiExits final : public ParRepFV
{

public:

  /** 
   * for do_dynamics(), we introduce 2 variants for generating multiple exit times:
   *  + one where exiting replica do nothing after exit and wait for the other replicas to join.
   *  + one where the exiting replica clones the status of one of the others and continues to run from this point.
   * 
   * This enum is for choosing the type of simulation to perform
   */
  enum multiExitType{
    MULTI_WAIT, ///< after exit, this replica waits and does nothing
    MULTI_CLONE ///< after exit, this replica clones crds and vels from another replica and runs again
  };

  /**
   * @brief The constructor
   * 
   * @param _dat Simulation data, see global.hpp
   * @param _at Array of coordinates and velocities
   * @param _md The MD interface
   * @param _luaItf The Lua interface
   * @param _max_allowed_events The maximum number of exit events to generate before the next F-V procedure should be initiated in a new-found state
   */
  ParRepFV_multiExits(DATA& _dat,
                      std::unique_ptr<ATOM[]>& _at,
                      std::unique_ptr<MD_interface>& _md,
                      std::unique_ptr<luaInterface>& _luaItf,
                      const uint32_t _max_allowed_events
                     );

  /**
   * @brief the main function running a Fleming-Viot ParRep with multi-exit simulation
   */
  virtual void run() override;
  
private:

  /** 
   * for calculating the exit time we need the number of processors doing the parrep phase and the mpi_id of the exiting replica
   *  
   *  for std parrep of generalized parrep with one exit this never changes ; but here with the multi exit version with wait, every time a replica exits we create
   *   a new parrep working group of reduced size, and furthermore the rankIDs change, so we need to keep trace of the number of workers and rank id as they
   *   were when an event occured.
   * 
   *  We also store if it is a first exit, a second, etc.
   * 
   *   for this purpose, when a replica exits it stores in the following struct the value of those variables, and they will be used for calculating the exit time
   */
  struct exitState_config final
  {
    
    /// only one type of constructor setting default values, no copy possible
    exitState_config()
    {
      global_mpi_id_when_exiting = -1;
      local_mpi_id_when_exiting = -1;
      num_workers_when_exiting = -1;
      exit_rank=-1;
      
      atomic_cfg = nullptr;
      
      time = 0.0;
      escape_time = 0.0;
    }
    int32_t global_mpi_id_when_exiting; ///< The id that the current MPI replica had at the beginning of the F-V procedure
    int32_t local_mpi_id_when_exiting;  ///< The local id that the current MPI replica had when exiting
    int32_t num_workers_when_exiting;   ///< How many workers were actually doing the job when exiting
    int32_t exit_rank;                  ///< the rank ID of the exiting replica
    
    std::unique_ptr<ATOM[]>         atomic_cfg; ///< Crds and vels config of the exiting replica
    std::array<PBC,3> pbc_cfg;    ///< Periodic boundary conditions of the exiting replica
    
    double time;        ///< physical time when exiting
    double escape_time; ///< exit_time will be stored there
    
    ENERGIES e;         ///< energies for the exiting replica
    
    sol::table serialized_state_def; ///< Lua table used for storing serialized data
  };
  
  /**
   * We use the MPI_MAXLOC operation to find simultaneously the max value of the escape time and its mpi index
   */
  struct maxloc_type{
    double  value;
    int32_t index;
  };
  
  /// will contain exit configurations generated by the do_dynamics_multi_... methods
  std::vector<exitState_config> exit_cfg;
  
  /// maximum number of allowed exit events
  const uint32_t allowed_exit_events;
  
  /// the type of multiple exit simulation to perform 
  multiExitType type;
  
  // when performing multiExit we may need a serialized definition of the states from lua to c++
  const ParRep_function_get_serialized_state& lua_get_serialized_state; ///< gets a serialized state from Lua 
  const ParRep_function_put_serialized_state& lua_put_serialized_state; ///< puts a serialized state to Lua 
  
  /**
   * @brief This performs the parallel dynamics stage.
   * 
   * for do_dynamics(), we introduce 2 variants for generating multiple exit times:
   *  + one where exiting replica do nothing after exit and wait for the other replicas to join.
   *  + one where the exiting replica clones the status of one of the others and continues to run from this point.
   */
  virtual void do_dynamics() override;
  
  /**
   * @brief This performs the parralel dynamics stage ; executed by all ranks at the same time,
   * and stopping when a given number of exit events have been performed
   * The exiting ranks wait for the others.
   * 
   * \note wasting of ressources but no extra correlation is induced
   */
  void do_dynamics_multi_wait();

  /**
   * @brief This performs the parralel dynamics stage ; executed by all ranks at the same time,
   * and stopping when a given number of exit events have been performed
   * The exiting ranks clone one of the others and continue to run.
   * 
   * \note optimal use of ressources but an extra correlation might be induced
   */
  void do_dynamics_multi_clone();
  
};

#endif // PARREP_FV_MULTI_HPP_INCLUDED
